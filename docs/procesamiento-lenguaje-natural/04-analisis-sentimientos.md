# üí¨ Unidad 4. An√°lisis de Sentimientos

El **An√°lisis de Sentimientos** (Sentiment Analysis), tambi√©n conocido como **miner√≠a de opiniones**, es una de las aplicaciones m√°s populares del NLP. Consiste en determinar la actitud, emoci√≥n u opini√≥n expresada en un texto.


![Ilustraci√≥n de sentiment](../assets/images/sentiment.svg)
---

## 4.1. ¬øQu√© es el An√°lisis de Sentimientos?

Es el proceso computacional de identificar y categorizar opiniones expresadas en texto para determinar si la actitud del escritor hacia un tema es:

*   **Positiva:** "Me encanta este producto, es incre√≠ble"
*   **Negativa:** "Terrible servicio, muy decepcionado"
*   **Neutral:** "El producto lleg√≥ ayer"

### Niveles de An√°lisis

| Nivel | Descripci√≥n | Ejemplo |
| :--- | :--- | :--- |
| **Documento** | Sentimiento global del texto | Rese√±a completa de un producto |
| **Oraci√≥n** | Sentimiento de cada oraci√≥n | Cada frase de una rese√±a |
| **Aspecto** | Sentimiento sobre aspectos espec√≠ficos | "La bater√≠a es excelente, pero la c√°mara es mala" |
| **Entidad** | Sentimiento hacia entidades espec√≠ficas | Opiniones sobre diferentes marcas en un texto |

### Tipos de Salida

*   **Binaria:** Positivo / Negativo
*   **Ternaria:** Positivo / Neutral / Negativo
*   **Escala:** Rating num√©rico (1-5 estrellas)
*   **Emociones:** Alegr√≠a, Tristeza, Ira, Miedo, Sorpresa, Disgusto

---

## 4.2. Enfoques para An√°lisis de Sentimientos

### Enfoque Basado en L√©xico

Utiliza diccionarios de palabras con polaridad predefinida.

**Ventajas:**

*   No requiere datos de entrenamiento.
*   Interpretable y transparente.
*   Funciona bien en dominios generales.

**Desventajas:**

*   No captura contexto ni negaciones bien.
*   Depende de la calidad del l√©xico.
*   Dificultad con sarcasmo e iron√≠a.

```python
# Ejemplo simple de enfoque l√©xico
lexico_positivo = {'bueno', 'excelente', 'genial', 'incre√≠ble', 'mejor', 'feliz', 'encanta'}
lexico_negativo = {'malo', 'terrible', 'horrible', 'peor', 'triste', 'odio', 'decepcionante'}

def analisis_lexico(texto):
    tokens = texto.lower().split()
    score = 0
    
    for token in tokens:
        if token in lexico_positivo:
            score += 1
        elif token in lexico_negativo:
            score -= 1
    
    if score > 0:
        return "Positivo"
    elif score < 0:
        return "Negativo"
    else:
        return "Neutral"

# Ejemplos
print(analisis_lexico("Este producto es excelente y genial"))  # Positivo
print(analisis_lexico("Terrible servicio, muy malo"))  # Negativo
print(analisis_lexico("El paquete lleg√≥ ayer"))  # Neutral
```

### Enfoque Basado en Machine Learning

Entrena clasificadores supervisados con datos etiquetados.

**Proceso t√≠pico:**

1.  Recolectar datos etiquetados (rese√±as con ratings).
2.  Preprocesar texto (tokenizaci√≥n, limpieza).
3.  Vectorizar (BoW, TF-IDF, embeddings).
4.  Entrenar clasificador (Naive Bayes, SVM, Logistic Regression).
5.  Evaluar y ajustar.

**Ventajas:**

*   Captura patrones complejos.
*   Adaptable a dominios espec√≠ficos.
*   Mejor rendimiento general.

**Desventajas:**

*   Requiere datos etiquetados.
*   Puede no generalizar a otros dominios.

---

## 4.3. Implementaci√≥n con Machine Learning

### Dataset: IMDB Movie Reviews

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.metrics import classification_report, accuracy_score

# Cargar datos (ejemplo simplificado)
# En la pr√°ctica, usar datasets como IMDB de Keras o Hugging Face
rese√±as = [
    ("me encanta esta pel√≠cula, actuaciones incre√≠bles", 1),
    ("pel√≠cula brillante, la recomiendo totalmente", 1),
    ("una historia hermosa y conmovedora", 1),
    ("excelente direcci√≥n y gui√≥n", 1),
    ("muy entretenida, la mejor del a√±o", 1),
    ("qu√© pel√≠cula tan aburrida y larga", 0),
    ("terrible actuaci√≥n, muy decepcionante", 0),
    ("perd√≠ mi tiempo viendo esto", 0),
    ("la peor pel√≠cula que he visto", 0),
    ("no la recomiendo para nada, muy mala", 0),
]

textos = [r[0] for r in rese√±as]
etiquetas = [r[1] for r in rese√±as]

# Divisi√≥n train/test
X_train, X_test, y_train, y_test = train_test_split(
    textos, etiquetas, test_size=0.3, random_state=42
)

# Vectorizaci√≥n TF-IDF
vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Entrenar m√∫ltiples modelos
modelos = {
    "Naive Bayes": MultinomialNB(),
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "SVM": LinearSVC()
}

for nombre, modelo in modelos.items():
    modelo.fit(X_train_tfidf, y_train)
    y_pred = modelo.predict(X_test_tfidf)
    acc = accuracy_score(y_test, y_pred)
    print(f"{nombre}: Accuracy = {acc:.4f}")
```

---

## 4.4. An√°lisis de Sentimientos con Bibliotecas

### TextBlob (R√°pido y Simple)

```python
from textblob import TextBlob

def analizar_sentimiento_textblob(texto):
    blob = TextBlob(texto)
    # Polaridad: -1 (negativo) a 1 (positivo)
    # Subjetividad: 0 (objetivo) a 1 (subjetivo)
    return {
        'texto': texto,
        'polaridad': blob.sentiment.polarity,
        'subjetividad': blob.sentiment.subjectivity,
        'sentimiento': 'Positivo' if blob.sentiment.polarity > 0 
                       else 'Negativo' if blob.sentiment.polarity < 0 
                       else 'Neutral'
    }

# Ejemplos
textos = [
    "I love this product, it's amazing!",
    "Terrible experience, very disappointed",
    "The package arrived yesterday"
]

for texto in textos:
    resultado = analizar_sentimiento_textblob(texto)
    print(f"{resultado['texto']}")
    print(f"  ‚Üí {resultado['sentimiento']} (pol: {resultado['polaridad']:.2f})")
    print()
```

### VADER (Especializado en Redes Sociales)

**VADER** (Valence Aware Dictionary for Sentiment Reasoning) est√° espec√≠ficamente dise√±ado para texto de redes sociales, manejando emojis, may√∫sculas, puntuaci√≥n, etc.

```python
from nltk.sentiment import SentimentIntensityAnalyzer
import nltk
nltk.download('vader_lexicon')

sia = SentimentIntensityAnalyzer()

textos = [
    "I LOVE this!!! üòç",
    "This is okay, nothing special",
    "Worst product EVER!!! üò°üò°üò°",
    "The movie was good, but the ending was bad"
]

for texto in textos:
    scores = sia.polarity_scores(texto)
    print(f"'{texto}'")
    print(f"  Scores: {scores}")
    print(f"  Compound: {scores['compound']:.3f}")
    print()
```

**Output de VADER:**

*   `neg`: Proporci√≥n negativa
*   `neu`: Proporci√≥n neutral
*   `pos`: Proporci√≥n positiva
*   `compound`: Score normalizado entre -1 y 1

---

## 4.5. An√°lisis de Sentimientos con Transformers

Los modelos basados en Transformers (BERT, RoBERTa) ofrecen el mejor rendimiento actual.

### Usando Hugging Face

```python
from transformers import pipeline

# Cargar pipeline de an√°lisis de sentimientos
sentiment_pipeline = pipeline("sentiment-analysis")

# An√°lisis simple
textos = [
    "I love this movie, it's fantastic!",
    "This is the worst product I've ever bought",
    "The weather is nice today"
]

for texto in textos:
    resultado = sentiment_pipeline(texto)[0]
    print(f"'{texto}'")
    print(f"  ‚Üí {resultado['label']} (score: {resultado['score']:.4f})")
    print()

# Para espa√±ol, usar modelo espec√≠fico
sentiment_es = pipeline(
    "sentiment-analysis", 
    model="nlptown/bert-base-multilingual-uncased-sentiment"
)

texto_es = "Esta pel√≠cula es absolutamente maravillosa"
resultado_es = sentiment_es(texto_es)
print(f"Espa√±ol: '{texto_es}' ‚Üí {resultado_es}")
```

### Modelo Espec√≠fico para Espa√±ol

```python
from transformers import pipeline

# Modelo entrenado espec√≠ficamente para espa√±ol
classifier = pipeline(
    "text-classification",
    model="pysentimiento/robertuito-sentiment-analysis"
)

textos_es = [
    "Me encanta este restaurante, la comida es deliciosa",
    "El servicio fue terrible y tardaron mucho",
    "El pedido lleg√≥ a tiempo"
]

for texto in textos_es:
    resultado = classifier(texto)[0]
    print(f"'{texto}'")
    print(f"  ‚Üí {resultado['label']} ({resultado['score']:.3f})")
```

---

## 4.6. An√°lisis de Sentimientos por Aspectos

El **Aspect-Based Sentiment Analysis (ABSA)** identifica sentimientos hacia aspectos espec√≠ficos de un producto o servicio.

```
"La bater√≠a del tel√©fono dura mucho, pero la c√°mara es terrible"

Aspectos:
- bater√≠a ‚Üí Positivo
- c√°mara ‚Üí Negativo
```

### Implementaci√≥n Simple

```python
import spacy

nlp = spacy.load('es_core_news_sm')

aspectos_positivos = {
    'bater√≠a': ['dura', 'excelente', 'incre√≠ble', 'buena'],
    'c√°mara': ['n√≠tida', 'clara', 'buena', 'incre√≠ble'],
    'pantalla': ['brillante', 'clara', 'grande', 'hermosa'],
    'dise√±o': ['elegante', 'bonito', 'moderno', 'hermoso']
}

aspectos_negativos = {
    'bater√≠a': ['corta', 'mala', 'terrible', 'poco'],
    'c√°mara': ['borrosa', 'mala', 'terrible', 'p√©sima'],
    'pantalla': ['peque√±a', 'oscura', 'mala'],
    'dise√±o': ['feo', 'malo', 'anticuado']
}

def absa_simple(texto):
    """An√°lisis de sentimiento por aspectos simple."""
    texto_lower = texto.lower()
    resultados = {}
    
    # Buscar aspectos y palabras de sentimiento cercanas
    for aspecto in aspectos_positivos.keys():
        if aspecto in texto_lower:
            sentimiento = "Neutral"
            
            # Buscar palabras positivas
            for palabra in aspectos_positivos[aspecto]:
                if palabra in texto_lower:
                    sentimiento = "Positivo"
                    break
            
            # Buscar palabras negativas
            for palabra in aspectos_negativos.get(aspecto, []):
                if palabra in texto_lower:
                    sentimiento = "Negativo"
                    break
            
            resultados[aspecto] = sentimiento
    
    return resultados

# Ejemplo
texto = "La bater√≠a es excelente y dura todo el d√≠a, pero la c√°mara es terrible y borrosa"
print(absa_simple(texto))
# {'bater√≠a': 'Positivo', 'c√°mara': 'Negativo'}
```

---

## 4.7. Aplicaciones Reales

### Monitoreo de Redes Sociales

```python
# Ejemplo: Analizar sentimiento de menciones de una marca
menciones = [
    "@MarcaX Gran servicio al cliente, muy satisfecho!",
    "@MarcaX El producto lleg√≥ da√±ado, muy decepcionado",
    "@MarcaX ¬øCu√°l es el horario de atenci√≥n?",
    "@MarcaX Incre√≠ble calidad, lo recomiendo totalmente",
    "@MarcaX El peor servicio que he recibido, jam√°s volver√©"
]

from collections import Counter

def monitorear_marca(menciones, classifier):
    """Analiza el sentimiento de menciones de una marca."""
    resultados = []
    
    for mencion in menciones:
        analisis = classifier(mencion)[0]
        resultados.append(analisis['label'])
    
    # Resumen
    conteo = Counter(resultados)
    total = len(resultados)
    
    print("=== Resumen de Sentimiento ===")
    for label, count in conteo.most_common():
        porcentaje = (count / total) * 100
        print(f"{label}: {count} ({porcentaje:.1f}%)")
    
    return resultados

# monitorear_marca(menciones, sentiment_pipeline)
```

### An√°lisis de Rese√±as de Productos

```python
def analizar_rese√±as_producto(rese√±as):
    """
    Analiza rese√±as de un producto y genera un resumen.
    """
    positivas = []
    negativas = []
    
    for rese√±a in rese√±as:
        # Aqu√≠ ir√≠a el clasificador
        # resultado = classifier(rese√±a)
        # Por simplicidad, usamos longitud como proxy
        if len(rese√±a) > 50 and "excelente" in rese√±a.lower():
            positivas.append(rese√±a)
        elif "malo" in rese√±a.lower() or "terrible" in rese√±a.lower():
            negativas.append(rese√±a)
    
    return {
        'total': len(rese√±as),
        'positivas': len(positivas),
        'negativas': len(negativas),
        'score': len(positivas) / max(len(rese√±as), 1)
    }
```

---

## 4.8. Desaf√≠os y Consideraciones

### Desaf√≠os Comunes

1.  **Sarcasmo e Iron√≠a:** "Oh genial, otro producto que no funciona" ‚Üí Detectado err√≥neamente como positivo.

2.  **Negaciones:** "No me gust√≥ nada" ‚Üí Palabras positivas ("gust√≥") en contexto negativo.

3.  **Comparaciones:** "Mejor que la competencia pero a√∫n malo" ‚Üí Mezcla de sentimientos.

4.  **Contexto del Dominio:** "La pel√≠cula es una bomba" ‚Üí Puede ser muy buena (√©xito) o muy mala (fracaso).

5.  **Multiling√ºe:** Modelos entrenados en ingl√©s no funcionan bien en espa√±ol sin adaptaci√≥n.

### M√©tricas de Evaluaci√≥n

| M√©trica | Uso |
| :--- | :--- |
| **Accuracy** | Proporci√≥n de predicciones correctas |
| **Precision** | De los predichos positivos, cu√°ntos son correctos |
| **Recall** | De los positivos reales, cu√°ntos detectamos |
| **F1-Score** | Media arm√≥nica de Precision y Recall |
| **Macro F1** | Promedio de F1 por clase (√∫til con clases desbalanceadas) |

---

üìÖ **Fecha de creaci√≥n:** Enero 2026  
‚úçÔ∏è **Autor:** Fran Garc√≠a
