# ğŸ” Unidad 7. Isolation Forest - DetecciÃ³n de AnomalÃ­as

**Isolation Forest** es un algoritmo de **detecciÃ³n de anomalÃ­as no supervisado** basado en Ã¡rboles de decisiÃ³n. A diferencia de otros mÃ©todos que intentan modelar los datos normales, Isolation Forest se enfoca en **aislar las anomalÃ­as**. La idea clave es que las anomalÃ­as son mÃ¡s fÃ¡ciles de aislar porque son raras y tienen valores atÃ­picos, lo que significa que requieren menos divisiones para separarlas del resto.


![IlustraciÃ³n de isolation forest](../assets/images/isolation_forest.svg)
---

## 7.1. Â¿CÃ³mo Funciona Isolation Forest?

### La IntuiciÃ³n

Imagina que tienes un bosque de puntos de datos. Si eliges un punto al azar y empiezas a hacer divisiones aleatorias:

- **Puntos normales:** EstÃ¡n en regiones densas, rodeados de muchos puntos â†’ necesitan muchas divisiones para ser aislados
- **AnomalÃ­as:** EstÃ¡n solos, lejos del resto â†’ se aÃ­slan con pocas divisiones

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INTUICIÃ“N DE ISOLATION FOREST                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚     Datos originales:                                       â”‚
â”‚                                                             â”‚
â”‚     â—â—â—â—â—â—             â† Cluster denso                     â”‚
â”‚     â—â—â—â—â—â—             (puntos normales)                   â”‚
â”‚     â—â—â—â—â—â—                                                 â”‚
â”‚                                                             â”‚
â”‚                                         âŠ— â† AnomalÃ­a       â”‚
â”‚                                                             â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                             â”‚
â”‚     Una divisiÃ³n aleatoria puede aislar la anomalÃ­a:       â”‚
â”‚                                                             â”‚
â”‚     â—â—â—â—â—â— â”‚                                               â”‚
â”‚     â—â—â—â—â—â— â”‚                                               â”‚
â”‚     â—â—â—â—â—â— â”‚                   âŠ— â† Â¡Aislada con 1 corte!   â”‚
â”‚            â”‚                                               â”‚
â”‚                                                             â”‚
â”‚     Pero un punto normal necesita mÃ¡s cortes:              â”‚
â”‚                                                             â”‚
â”‚     â—â—â”€â”¬â”€â—â— â”‚                                              â”‚
â”‚     â—â—â”€â”¼â”€â—â— â”‚    Necesita 3+ cortes para                   â”‚
â”‚     â—â—â”€â”´â”€â—â— â”‚    aislar un punto del cluster               â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### El Algoritmo

1. **Construir mÃºltiples Ã¡rboles de aislamiento (iForest)**
2. Para cada Ã¡rbol:
   - Seleccionar aleatoriamente un subconjunto de datos
   - Seleccionar aleatoriamente una caracterÃ­stica
   - Seleccionar aleatoriamente un valor de corte entre min y max
   - Dividir los datos recursivamente hasta que cada punto quede aislado o se alcance un lÃ­mite
3. **Calcular la "path length"** (longitud del camino) promedio para cada punto
4. **Puntos con path length corta = AnomalÃ­as**

---

## 7.2. ExplicaciÃ³n MatemÃ¡tica

### Path Length (Longitud del Camino)

La **path length** $h(x)$ de un punto $x$ es el nÃºmero de divisiones necesarias para aislar ese punto desde la raÃ­z hasta el nodo terminal.

Para un punto $x$, calculamos el **path length promedio** sobre todos los Ã¡rboles:
$$E[h(x)] = \frac{1}{t} \sum_{i=1}^{t} h_i(x)$$

Donde $t$ es el nÃºmero de Ã¡rboles y $h_i(x)$ es la path length en el Ã¡rbol $i$.

### Path Length Esperada

Para un Ã¡rbol binario construido con $n$ puntos, la path length promedio esperada para un punto **normal** es aproximadamente:

$$c(n) = 2H(n-1) - \frac{2(n-1)}{n}$$

Donde $H(i)$ es el nÃºmero harmÃ³nico: $H(i) = \ln(i) + \gamma$ (Î³ â‰ˆ 0.5772 es la constante de Euler-Mascheroni).

### Anomaly Score

El **anomaly score** normaliza la path length:

$$s(x, n) = 2^{-\frac{E[h(x)]}{c(n)}}$$

**InterpretaciÃ³n:**
- $s(x, n) \approx 1$: Punto es una anomalÃ­a (path length muy corta)
- $s(x, n) \approx 0.5$: Punto normal (path length promedio)
- $s(x, n) < 0.5$: Punto muy normal (path length larga)

```
      Anomaly Score
      
      1.0 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ âŠ— AnomalÃ­as
          
      0.5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â— Puntos normales
          
      0.0 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

---

## 7.3. Pros y Contras

| Ventajas | Desventajas |
| :--- | :--- |
| **No necesita etiquetas:** Completamente no supervisado | **Sensible a contaminaciÃ³n:** El parÃ¡metro contamination afecta mucho |
| **Muy eficiente:** Complejidad $O(n \log n)$ | **No ideal para datos de alta dimensiÃ³n:** Pierde efectividad |
| **Escalable:** Funciona bien con datasets grandes | **Asume anomalÃ­as son aislables:** No funciona si las anomalÃ­as forman clusters |
| **Robusto:** No asume distribuciÃ³n de los datos | **No probabilÃ­stico:** Solo da scores, no probabilidades |
| **Pocos hiperparÃ¡metros:** FÃ¡cil de configurar | **Puede perder anomalÃ­as sutiles:** Si estÃ¡n cerca de datos normales |

---

## 7.4. Ejemplo BÃ¡sico en Python

Este ejemplo muestra el uso bÃ¡sico de Isolation Forest para detectar anomalÃ­as.

```python
# ============================================================
# EJEMPLO BÃSICO: Isolation Forest para detecciÃ³n de anomalÃ­as
# ============================================================

# Importar bibliotecas necesarias
import numpy as np                          # Operaciones numÃ©ricas
import matplotlib.pyplot as plt             # VisualizaciÃ³n
from sklearn.ensemble import IsolationForest  # Algoritmo principal
from sklearn.datasets import make_blobs     # Generar datos sintÃ©ticos

# -------------------------------------------------------------
# 1. CREAR DATOS CON ANOMALÃAS
# -------------------------------------------------------------
# Generar datos normales (cluster)
np.random.seed(42)
X_normal, _ = make_blobs(n_samples=300, centers=1, cluster_std=1.0, random_state=42)

# AÃ±adir anomalÃ­as (puntos lejanos del cluster)
n_anomalies = 20
X_anomalies = np.random.uniform(low=-6, high=6, size=(n_anomalies, 2))

# Combinar datos
X = np.vstack([X_normal, X_anomalies])

# Crear etiquetas verdaderas para evaluaciÃ³n
# 1 = normal, -1 = anomalÃ­a
y_true = np.array([1] * len(X_normal) + [-1] * n_anomalies)

print("="*50)
print("ISOLATION FOREST - DETECCIÃ“N DE ANOMALÃAS")
print("="*50)
print(f"\nTotal de puntos: {len(X)}")
print(f"Puntos normales: {len(X_normal)}")
print(f"AnomalÃ­as verdaderas: {n_anomalies}")
print(f"Tasa de contaminaciÃ³n real: {n_anomalies/len(X):.2%}")

# -------------------------------------------------------------
# 2. VISUALIZAR DATOS ORIGINALES
# -------------------------------------------------------------
plt.figure(figsize=(10, 4))

plt.subplot(1, 2, 1)
plt.scatter(X_normal[:, 0], X_normal[:, 1], c='blue', alpha=0.6, label='Normal', s=30)
plt.scatter(X_anomalies[:, 0], X_anomalies[:, 1], c='red', marker='x', s=100, 
            label='AnomalÃ­as', linewidths=2)
plt.xlabel('CaracterÃ­stica 1')
plt.ylabel('CaracterÃ­stica 2')
plt.title('Datos Originales (con etiquetas verdaderas)')
plt.legend()
plt.grid(True, alpha=0.3)

# -------------------------------------------------------------
# 3. APLICAR ISOLATION FOREST
# -------------------------------------------------------------
# Crear y entrenar el modelo
# contamination: proporciÃ³n esperada de anomalÃ­as
iso_forest = IsolationForest(
    n_estimators=100,           # NÃºmero de Ã¡rboles
    contamination=0.1,          # ProporciÃ³n esperada de anomalÃ­as (10%)
    random_state=42,            # Reproducibilidad
    max_samples='auto'          # Muestras por Ã¡rbol
)

# Entrenar y predecir
# fit_predict devuelve: 1 (normal), -1 (anomalÃ­a)
y_pred = iso_forest.fit_predict(X)

# -------------------------------------------------------------
# 4. ANALIZAR RESULTADOS
# -------------------------------------------------------------
# Contar predicciones
n_pred_normal = np.sum(y_pred == 1)
n_pred_anomaly = np.sum(y_pred == -1)

print(f"\n--- Resultados de Isolation Forest ---")
print(f"Predichos como normal: {n_pred_normal}")
print(f"Predichos como anomalÃ­a: {n_pred_anomaly}")

# Calcular mÃ©tricas de rendimiento
from sklearn.metrics import classification_report, confusion_matrix

# Convertir etiquetas para mÃ©tricas
print(f"\n--- Reporte de ClasificaciÃ³n ---")
print(classification_report(y_true, y_pred, target_names=['AnomalÃ­a (-1)', 'Normal (1)']))

# Matriz de confusiÃ³n
cm = confusion_matrix(y_true, y_pred)
print(f"Matriz de ConfusiÃ³n:")
print(f"                 Predicho AnomalÃ­a | Predicho Normal")
print(f"Real AnomalÃ­a:          {cm[0,0]:4d}      |      {cm[0,1]:4d}")
print(f"Real Normal:            {cm[1,0]:4d}      |      {cm[1,1]:4d}")

# -------------------------------------------------------------
# 5. VISUALIZAR PREDICCIONES
# -------------------------------------------------------------
plt.subplot(1, 2, 2)

# Separar por predicciÃ³n
mask_pred_normal = y_pred == 1
mask_pred_anomaly = y_pred == -1

plt.scatter(X[mask_pred_normal, 0], X[mask_pred_normal, 1], 
            c='green', alpha=0.6, label='Predicho Normal', s=30)
plt.scatter(X[mask_pred_anomaly, 0], X[mask_pred_anomaly, 1], 
            c='red', marker='x', s=100, label='Predicho AnomalÃ­a', linewidths=2)

plt.xlabel('CaracterÃ­stica 1')
plt.ylabel('CaracterÃ­stica 2')
plt.title('Predicciones de Isolation Forest')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# -------------------------------------------------------------
# 6. OBTENER ANOMALY SCORES
# -------------------------------------------------------------
# decision_function devuelve el score de anomalÃ­a
# Valores mÃ¡s negativos = mÃ¡s anÃ³malo
scores = iso_forest.decision_function(X)

# score_samples devuelve valores similares (opuesto de la depth)
# Valores mÃ¡s negativos = mÃ¡s anÃ³malo

print(f"\n--- Anomaly Scores ---")
print(f"Score medio (normales): {scores[y_true == 1].mean():.3f}")
print(f"Score medio (anomalÃ­as): {scores[y_true == -1].mean():.3f}")
print(f"Rango de scores: [{scores.min():.3f}, {scores.max():.3f}]")

# Visualizar distribuciÃ³n de scores
plt.figure(figsize=(10, 4))

plt.subplot(1, 2, 1)
plt.hist(scores[y_true == 1], bins=30, alpha=0.7, label='Normal', color='blue')
plt.hist(scores[y_true == -1], bins=10, alpha=0.7, label='AnomalÃ­a', color='red')
plt.xlabel('Anomaly Score (decision_function)')
plt.ylabel('Frecuencia')
plt.title('DistribuciÃ³n de Anomaly Scores')
plt.legend()
plt.axvline(x=0, color='black', linestyle='--', label='Umbral (0)')

plt.subplot(1, 2, 2)
# Colorear puntos por score
scatter = plt.scatter(X[:, 0], X[:, 1], c=scores, cmap='RdYlGn', 
                      alpha=0.7, s=30, edgecolors='k', linewidths=0.5)
plt.colorbar(scatter, label='Anomaly Score')
plt.xlabel('CaracterÃ­stica 1')
plt.ylabel('CaracterÃ­stica 2')
plt.title('Mapa de Anomaly Scores\n(Verde=Normal, Rojo=AnomalÃ­a)')

plt.tight_layout()
plt.show()

print("""
InterpretaciÃ³n de decision_function:
- Valores positivos â†’ punto probablemente normal
- Valores negativos â†’ punto probablemente anÃ³malo
- El umbral por defecto es 0 (controlado por contamination)
""")
```

---

## 7.5. Ejemplo Avanzado: AnÃ¡lisis de HiperparÃ¡metros y Casos de Uso

Este ejemplo explora la configuraciÃ³n Ã³ptima y casos de uso reales.

```python
# ============================================================
# EJEMPLO AVANZADO: Isolation Forest - AnÃ¡lisis profundo
# ============================================================

import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc
import warnings
warnings.filterwarnings('ignore')

# -------------------------------------------------------------
# 1. CREAR DATASET COMPLEJO
# -------------------------------------------------------------
np.random.seed(42)

# Datos normales: dos clusters
from sklearn.datasets import make_blobs
X_normal1, _ = make_blobs(n_samples=400, centers=[[2, 2]], cluster_std=0.8)
X_normal2, _ = make_blobs(n_samples=400, centers=[[-2, -2]], cluster_std=0.8)
X_normal = np.vstack([X_normal1, X_normal2])

# AnomalÃ­as de diferentes tipos
anomalies_global = np.random.uniform(-6, 6, (15, 2))  # Aleatorias
anomalies_local = np.array([[0, 0], [0.5, 0.5], [-0.5, -0.5]])  # Entre clusters
anomalies_edge = np.array([[4, 2], [2, 4], [-4, -2]])  # En bordes

X_anomalies = np.vstack([anomalies_global, anomalies_local, anomalies_edge])

X = np.vstack([X_normal, X_anomalies])
y_true = np.array([1] * len(X_normal) + [-1] * len(X_anomalies))

print("="*60)
print("ISOLATION FOREST - ANÃLISIS AVANZADO")
print("="*60)
print(f"\nDataset: {len(X)} puntos ({len(X_normal)} normales, {len(X_anomalies)} anomalÃ­as)")

# -------------------------------------------------------------
# 2. EFECTO DEL NÃšMERO DE ESTIMADORES
# -------------------------------------------------------------
print("\n[1] EFECTO DEL NÃšMERO DE ESTIMADORES (n_estimators)")
print("-"*50)

n_estimators_list = [10, 50, 100, 200, 500]
results_estimators = []

for n_est in n_estimators_list:
    iso = IsolationForest(n_estimators=n_est, contamination=0.05, random_state=42)
    y_pred = iso.fit_predict(X)
    f1 = f1_score(y_true, y_pred, pos_label=-1)
    results_estimators.append(f1)
    print(f"  n_estimators={n_est:3d}: F1={f1:.3f}")

plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.plot(n_estimators_list, results_estimators, 'bo-', linewidth=2, markersize=8)
plt.xlabel('NÃºmero de Estimadores')
plt.ylabel('F1-Score (AnomalÃ­as)')
plt.title('Efecto del NÃºmero de Ãrboles')
plt.grid(True, alpha=0.3)

# -------------------------------------------------------------
# 3. EFECTO DE LA CONTAMINACIÃ“N
# -------------------------------------------------------------
print("\n[2] EFECTO DE LA CONTAMINACIÃ“N (contamination)")
print("-"*50)

contamination_list = [0.01, 0.03, 0.05, 0.1, 0.15, 0.2]
results_contamination = {'precision': [], 'recall': [], 'f1': []}

for cont in contamination_list:
    iso = IsolationForest(n_estimators=100, contamination=cont, random_state=42)
    y_pred = iso.fit_predict(X)
    
    prec = precision_score(y_true, y_pred, pos_label=-1)
    rec = recall_score(y_true, y_pred, pos_label=-1)
    f1 = f1_score(y_true, y_pred, pos_label=-1)
    
    results_contamination['precision'].append(prec)
    results_contamination['recall'].append(rec)
    results_contamination['f1'].append(f1)
    
    print(f"  contamination={cont:.2f}: Precision={prec:.3f}, Recall={rec:.3f}, F1={f1:.3f}")

plt.subplot(1, 2, 2)
plt.plot(contamination_list, results_contamination['precision'], 'g^-', label='Precision', linewidth=2)
plt.plot(contamination_list, results_contamination['recall'], 'rs-', label='Recall', linewidth=2)
plt.plot(contamination_list, results_contamination['f1'], 'bo-', label='F1-Score', linewidth=2)
plt.axvline(x=len(X_anomalies)/len(X), color='k', linestyle='--', alpha=0.5, label='Contam. real')
plt.xlabel('Contamination')
plt.ylabel('Score')
plt.title('Efecto del ParÃ¡metro Contamination')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f"\nContaminaciÃ³n real en los datos: {len(X_anomalies)/len(X):.3f}")

# -------------------------------------------------------------
# 4. EFECTO DE max_samples
# -------------------------------------------------------------
print("\n[3] EFECTO DE max_samples")
print("-"*50)

max_samples_list = [32, 64, 128, 256, 'auto']
results_samples = []

for max_s in max_samples_list:
    iso = IsolationForest(n_estimators=100, contamination=0.05, 
                          max_samples=max_s, random_state=42)
    y_pred = iso.fit_predict(X)
    f1 = f1_score(y_true, y_pred, pos_label=-1)
    results_samples.append(f1)
    print(f"  max_samples={str(max_s):5s}: F1={f1:.3f}")

# -------------------------------------------------------------
# 5. CURVA ROC CON DIFERENTES UMBRALES
# -------------------------------------------------------------
print("\n[4] ANÃLISIS DE UMBRALES Y CURVA ROC")
print("-"*50)

# Entrenar modelo
iso = IsolationForest(n_estimators=100, random_state=42)
iso.fit(X)

# Obtener scores (invertir signo para ROC)
scores = -iso.decision_function(X)  # MÃ¡s alto = mÃ¡s anÃ³malo

# Calcular ROC
fpr, tpr, thresholds = roc_curve(y_true == -1, scores)
roc_auc = auc(fpr, tpr)

print(f"  AUC-ROC: {roc_auc:.3f}")

plt.figure(figsize=(12, 4))

plt.subplot(1, 3, 1)
plt.plot(fpr, tpr, 'b-', linewidth=2, label=f'AUC = {roc_auc:.3f}')
plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Curva ROC')
plt.legend()
plt.grid(True, alpha=0.3)

# Visualizar diferentes umbrales
plt.subplot(1, 3, 2)

# Umbral automÃ¡tico (contamination=0.05)
iso_auto = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)
y_pred_auto = iso_auto.fit_predict(X)

mask_normal = y_pred_auto == 1
mask_anomaly = y_pred_auto == -1

plt.scatter(X[mask_normal, 0], X[mask_normal, 1], c='blue', alpha=0.5, s=20, label='Normal')
plt.scatter(X[mask_anomaly, 0], X[mask_anomaly, 1], c='red', marker='x', s=80, 
            label='AnomalÃ­a', linewidths=2)
plt.title('Contamination = 5%')
plt.legend()

# Umbral mÃ¡s estricto
plt.subplot(1, 3, 3)

iso_strict = IsolationForest(n_estimators=100, contamination=0.02, random_state=42)
y_pred_strict = iso_strict.fit_predict(X)

mask_normal = y_pred_strict == 1
mask_anomaly = y_pred_strict == -1

plt.scatter(X[mask_normal, 0], X[mask_normal, 1], c='blue', alpha=0.5, s=20, label='Normal')
plt.scatter(X[mask_anomaly, 0], X[mask_anomaly, 1], c='red', marker='x', s=80, 
            label='AnomalÃ­a', linewidths=2)
plt.title('Contamination = 2%')
plt.legend()

plt.tight_layout()
plt.show()

# -------------------------------------------------------------
# 6. VISUALIZAR REGIONES DE DECISIÃ“N
# -------------------------------------------------------------
print("\n[5] VISUALIZACIÃ“N DE REGIONES DE DECISIÃ“N")
print("-"*50)

# Crear grid para visualizaciÃ³n
xx, yy = np.meshgrid(np.linspace(-7, 7, 150), np.linspace(-7, 7, 150))
grid = np.c_[xx.ravel(), yy.ravel()]

# Entrenar modelo
iso = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)
iso.fit(X)

# Obtener scores para el grid
Z = iso.decision_function(grid)
Z = Z.reshape(xx.shape)

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
# Contour de scores
contour = plt.contourf(xx, yy, Z, levels=20, cmap='RdYlGn', alpha=0.8)
plt.colorbar(contour, label='Anomaly Score')

# Puntos reales
plt.scatter(X[y_true == 1, 0], X[y_true == 1, 1], c='blue', edgecolors='k', 
            s=20, alpha=0.6, label='Normal')
plt.scatter(X[y_true == -1, 0], X[y_true == -1, 1], c='red', marker='x',
            s=100, linewidths=2, label='AnomalÃ­a real')

plt.xlabel('CaracterÃ­stica 1')
plt.ylabel('CaracterÃ­stica 2')
plt.title('Mapa de Anomaly Scores\n(Verde=Normal, Rojo=AnÃ³malo)')
plt.legend()

plt.subplot(1, 2, 2)
# Frontera de decisiÃ³n
plt.contour(xx, yy, Z, levels=[0], colors='black', linewidths=2)
plt.contourf(xx, yy, Z, levels=[Z.min(), 0], colors=['red'], alpha=0.3)
plt.contourf(xx, yy, Z, levels=[0, Z.max()], colors=['green'], alpha=0.3)

plt.scatter(X[y_true == 1, 0], X[y_true == 1, 1], c='blue', edgecolors='k',
            s=20, alpha=0.6, label='Normal')
plt.scatter(X[y_true == -1, 0], X[y_true == -1, 1], c='red', marker='x',
            s=100, linewidths=2, label='AnomalÃ­a real')

plt.xlabel('CaracterÃ­stica 1')
plt.ylabel('CaracterÃ­stica 2')
plt.title('Frontera de DecisiÃ³n\n(Rojo=RegiÃ³n anÃ³mala)')
plt.legend()

plt.tight_layout()
plt.show()

# -------------------------------------------------------------
# 7. CASO REAL: DETECCIÃ“N DE FRAUDE (SIMULADO)
# -------------------------------------------------------------
print("\n[6] CASO DE USO: DETECCIÃ“N DE FRAUDE")
print("-"*50)

# Simular datos de transacciones
np.random.seed(42)
n_normal = 10000
n_fraud = 100  # 1% de fraude

# Transacciones normales: monto bajo-medio, hora comercial
normal_amount = np.abs(np.random.normal(50, 30, n_normal))
normal_hour = np.random.normal(14, 4, n_normal)  # Centrado en 2pm
normal_hour = np.clip(normal_hour, 0, 24)

# Transacciones fraudulentas: montos altos, horas inusuales
fraud_amount = np.abs(np.random.normal(500, 200, n_fraud))
fraud_hour = np.random.uniform(0, 6, n_fraud)  # Madrugada

# Combinar
X_fraud = np.column_stack([
    np.concatenate([normal_amount, fraud_amount]),
    np.concatenate([normal_hour, fraud_hour])
])
y_fraud = np.array([1] * n_normal + [-1] * n_fraud)

# Estandarizar
scaler = StandardScaler()
X_fraud_scaled = scaler.fit_transform(X_fraud)

# Entrenar Isolation Forest
iso_fraud = IsolationForest(n_estimators=100, contamination=0.01, random_state=42)
y_pred_fraud = iso_fraud.fit_predict(X_fraud_scaled)

# Resultados
print(f"  Transacciones totales: {len(X_fraud):,}")
print(f"  Fraudes reales: {n_fraud}")
print(f"  Fraudes detectados: {np.sum(y_pred_fraud == -1)}")

# MÃ©tricas
prec = precision_score(y_fraud, y_pred_fraud, pos_label=-1)
rec = recall_score(y_fraud, y_pred_fraud, pos_label=-1)
f1 = f1_score(y_fraud, y_pred_fraud, pos_label=-1)

print(f"\n  Precision: {prec:.3f} (De los detectados, quÃ© % son fraude)")
print(f"  Recall: {rec:.3f} (De los fraudes reales, quÃ© % detectamos)")
print(f"  F1-Score: {f1:.3f}")

# Visualizar
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.scatter(X_fraud[y_fraud == 1, 0], X_fraud[y_fraud == 1, 1], 
            c='green', alpha=0.3, s=5, label='Normal')
plt.scatter(X_fraud[y_fraud == -1, 0], X_fraud[y_fraud == -1, 1],
            c='red', marker='x', s=50, label='Fraude real')
plt.xlabel('Monto ($)')
plt.ylabel('Hora del dÃ­a')
plt.title('Datos Reales')
plt.legend()

plt.subplot(1, 2, 2)
plt.scatter(X_fraud[y_pred_fraud == 1, 0], X_fraud[y_pred_fraud == 1, 1],
            c='green', alpha=0.3, s=5, label='Predicho Normal')
plt.scatter(X_fraud[y_pred_fraud == -1, 0], X_fraud[y_pred_fraud == -1, 1],
            c='red', marker='x', s=50, label='Predicho Fraude')
plt.xlabel('Monto ($)')
plt.ylabel('Hora del dÃ­a')
plt.title('Predicciones de Isolation Forest')
plt.legend()

plt.tight_layout()
plt.show()

# -------------------------------------------------------------
# 8. MEJORES PRÃCTICAS
# -------------------------------------------------------------
print("\n" + "="*60)
print("MEJORES PRÃCTICAS PARA ISOLATION FOREST")
print("="*60)

print("""
1. PREPROCESAMIENTO:
   - Estandarizar/normalizar las caracterÃ­sticas
   - Considerar encoding adecuado para categorÃ­as
   - Manejar valores faltantes antes

2. HIPERPARÃMETROS:
   - n_estimators: 100 suele ser suficiente
   - contamination: Usar conocimiento del dominio si es posible
   - max_samples: 'auto' o sqrt(n_samples)

3. EVALUACIÃ“N:
   - Si hay etiquetas: Precision, Recall, F1, AUC-ROC
   - Sin etiquetas: InspecciÃ³n manual de anomalÃ­as detectadas
   - Analizar distribuciÃ³n de scores

4. CONSIDERACIONES:
   - No asume distribuciÃ³n de los datos
   - Funciona mejor con anomalÃ­as globales/aisladas
   - Puede fallar con anomalÃ­as en clusters
   - Revisar puntos cerca del umbral manualmente
""")

print("\n" + "="*60)
print("ANÃLISIS COMPLETADO")
print("="*60)
```

---

## 7.6. HiperparÃ¡metros de Isolation Forest en scikit-learn

| ParÃ¡metro | DescripciÃ³n | Valores | RecomendaciÃ³n |
| :--- | :--- | :--- | :--- |
| `n_estimators` | NÃºmero de Ã¡rboles | int > 0 | 100 (mÃ¡s = mÃ¡s estable) |
| `contamination` | ProporciÃ³n esperada de anomalÃ­as | float (0, 0.5) o 'auto' | Basado en conocimiento del dominio |
| `max_samples` | Muestras por Ã¡rbol | int, float, 'auto' | 'auto' (min(256, n_samples)) |
| `max_features` | CaracterÃ­sticas por Ã¡rbol | int o float | 1.0 (todas) |
| `bootstrap` | Muestreo con reemplazo | bool | False |
| `random_state` | Semilla | int o None | Fijar para reproducibilidad |
| `n_jobs` | Procesadores paralelos | int | -1 para usar todos |
| `warm_start` | AÃ±adir Ã¡rboles incrementalmente | bool | False |

---

## 7.7. Aplicaciones Reales

### 1. DetecciÃ³n de Fraude Financiero
Identificar transacciones sospechosas en tarjetas de crÃ©dito.
* [Ejemplo: Credit Card Fraud Detection](https://www.kaggle.com/code/janiobachmann/credit-fraud-dealing-with-imbalanced-datasets)

### 2. DetecciÃ³n de Intrusiones en Redes
Identificar patrones de trÃ¡fico anÃ³malos que puedan indicar ataques.

### 3. Mantenimiento Predictivo
Detectar comportamientos anÃ³malos en sensores de maquinaria industrial.

### 4. Control de Calidad
Identificar productos defectuosos en lÃ­neas de producciÃ³n.

### 5. Salud
Detectar patrones anÃ³malos en datos mÃ©dicos (ECG, diagnÃ³sticos).

---

## 7.8. ComparaciÃ³n con Otros MÃ©todos de DetecciÃ³n de AnomalÃ­as

| MÃ©todo | Tipo | Velocidad | Escalabilidad | Mejor para |
| :--- | :--- | :--- | :--- | :--- |
| **Isolation Forest** | Basado en Ã¡rboles | RÃ¡pido | Excelente | AnomalÃ­as globales |
| **One-Class SVM** | Basado en kernel | Lento | Pobre | Datasets pequeÃ±os |
| **LOF** | Basado en densidad | Medio | Media | AnomalÃ­as locales |
| **DBSCAN** | Clustering | Medio | Buena | Clusters + anomalÃ­as |
| **Autoencoder** | Deep Learning | Lento (train) | Buena | Alta dimensionalidad |

---

## 7.9. Resumen y Checklist

### Checklist para usar Isolation Forest

- [ ] **Preprocesar los datos** (estandarizar, manejar NaN)
- [ ] **Estimar contamination** si es posible
- [ ] **Empezar con n_estimators=100**
- [ ] **Visualizar anomaly scores** para entender la distribuciÃ³n
- [ ] **Ajustar contamination** segÃºn resultados
- [ ] **Validar con mÃ©tricas** si hay etiquetas disponibles
- [ ] **Inspeccionar manualmente** las anomalÃ­as detectadas

### Â¿CuÃ¡ndo usar Isolation Forest?

âœ… **Usar Isolation Forest cuando:**
- Tienes un dataset grande
- Las anomalÃ­as son raras y diferentes al resto
- No tienes etiquetas de anomalÃ­as
- Necesitas un mÃ©todo rÃ¡pido y escalable

âŒ **Considerar alternativas cuando:**
- Las anomalÃ­as forman clusters â†’ LOF o DBSCAN
- Dataset muy pequeÃ±o â†’ One-Class SVM
- Datos de alta dimensiÃ³n complejos â†’ Autoencoders
- Necesitas probabilidades â†’ Gaussian Mixture

---

ğŸ“… **Fecha de creaciÃ³n:** Enero 2026  
âœï¸ **Autor:** Fran GarcÃ­a
