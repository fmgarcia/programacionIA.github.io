#  Deep Learning

隆Bienvenido a la secci贸n de Deep Learning! 

---

##  驴Qu茅 es el Deep Learning?

El **Deep Learning** (Aprendizaje Profundo) es un subcampo del Machine Learning que utiliza **redes neuronales artificiales** con m煤ltiples capas (de ah铆 el t茅rmino "profundo") para aprender representaciones jer谩rquicas de los datos.

A diferencia de los algoritmos tradicionales de ML que requieren ingenier铆a de caracter铆sticas manual, el Deep Learning puede aprender autom谩ticamente las caracter铆sticas relevantes directamente de los datos en bruto.

---

##  Arquitecturas Principales

1. **Redes Neuronales Artificiales (ANN):**  
   La base del Deep Learning, inspirada en el cerebro humano.  
    *Uso:* Clasificaci贸n, regresi贸n.

2. **Redes Neuronales Convolucionales (CNN):**  
   Especializadas en procesar datos con estructura de cuadr铆cula (im谩genes).  
    *Uso:* Visi贸n por computadora, clasificaci贸n de im谩genes, detecci贸n de objetos.

3. **Redes Neuronales Recurrentes (RNN):**  
   Dise帽adas para datos secuenciales con memoria de estados anteriores.  
    *Uso:* Series temporales, texto.

4. **LSTM y GRU:**  
   Variantes de RNN que solucionan el problema del gradiente desvaneciente.  
    *Uso:* Secuencias largas, traducci贸n.

5. **Transformers:**  
   Arquitectura basada en mecanismos de atenci贸n, revolucion贸 el NLP y m谩s.  
    *Uso:* GPT, BERT, modelos de lenguaje grandes (LLMs).

6. **Autoencoders:**  
   Redes que aprenden representaciones comprimidas de los datos.  
    *Uso:* Reducci贸n de dimensionalidad, generaci贸n.

7. **GANs (Redes Generativas Adversarias):**  
   Dos redes que compiten para generar datos realistas.  
    *Uso:* Generaci贸n de im谩genes, arte, deepfakes.

---

## 锔 Conceptos Fundamentales

- **Neurona artificial:** Unidad b谩sica que aplica pesos, bias y funci贸n de activaci贸n
- **Capas:** Entrada, ocultas y salida
- **Funciones de activaci贸n:** ReLU, Sigmoid, Tanh, Softmax
- **Backpropagation:** Algoritmo para calcular gradientes
- **Optimizadores:** SGD, Adam, RMSprop
- **Regularizaci贸n:** Dropout, L1/L2, Batch Normalization
- **Transfer Learning:** Reutilizar modelos preentrenados

---

##  Frameworks Populares

- **TensorFlow** - Framework de Google
- **Keras** - API de alto nivel (integrada en TensorFlow)
- **PyTorch** - Framework de Meta, muy usado en investigaci贸n
- **JAX** - Computaci贸n num茅rica de alto rendimiento

---

##  Contenido en construcci贸n

Esta secci贸n est谩 siendo desarrollada. Pr贸ximamente encontrar谩s:

- [ ] Fundamentos de redes neuronales
- [ ] Redes convolucionales (CNN)
- [ ] Redes recurrentes (RNN, LSTM)
- [ ] Transformers y atenci贸n
- [ ] Ejemplos pr谩cticos con TensorFlow/PyTorch

---

 **Fecha de creaci贸n:** Enero 2026  
锔 **Autor:** Fran Garc铆a
