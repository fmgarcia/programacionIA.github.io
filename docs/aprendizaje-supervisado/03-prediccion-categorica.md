#  Unidad 3. Modelos de Aprendizaje Supervisado para Predicci贸n Categ贸rica

La **clasificaci贸n** es una subcategor铆a del aprendizaje supervisado donde el objetivo es predecir una etiqueta de clase categ贸rica (discreta) para una instancia de datos dada. A diferencia de la regresi贸n, que predice valores continuos, la clasificaci贸n asigna entradas a una de varias categor铆as predefinidas.

---

### 3.1. Entrenamiento y Testing en Clasificaci贸n

El proceso de construcci贸n de un modelo de clasificaci贸n sigue el flujo est谩ndar de Machine Learning:

1.  **Divisi贸n de Datos:** Se divide el dataset en un conjunto de **entrenamiento** (para ajustar el modelo) y un conjunto de **prueba** (para evaluar su rendimiento en datos no vistos).
2.  **Entrenamiento:** El algoritmo aprende la frontera de decisi贸n que separa las diferentes clases bas谩ndose en las caracter铆sticas (features) de los datos de entrenamiento.
3.  **Testing (Predicci贸n):** El modelo asigna etiquetas a los datos de prueba.
4.  **Evaluaci贸n:** Se comparan las etiquetas predichas con las etiquetas reales para calcular m茅tricas de rendimiento.

---

### 3.2. Ejemplos Frecuentes de Uso

La clasificaci贸n est谩 omnipresente en aplicaciones modernas:

*   **Detecci贸n de Spam:** Clasificar correos como "Spam" o "No Spam".
*   **Diagn贸stico M茅dico:** Determinar si un paciente tiene una enfermedad ("Positivo") o no ("Negativo") bas谩ndose en s铆ntomas y an谩lisis.
*   **Reconocimiento de Im谩genes:** Identificar si una imagen contiene un "Gato", "Perro" o "Coche".
*   **Aprobaci贸n de Cr茅ditos:** Clasificar a un solicitante como de "Alto Riesgo" o "Bajo Riesgo".
*   **An谩lisis de Sentimientos:** Clasificar opiniones como "Positivas", "Negativas" o "Neutrales".

---

### 3.3. Algoritmos de Clasificaci贸n en Machine Learning

Existen diversos algoritmos para abordar problemas de clasificaci贸n:

*   **Regresi贸n Log铆stica:** Simple, interpretable y base para redes neuronales.
*   **K-Nearest Neighbors (KNN):** Basado en similitud y distancia.
*   **Support Vector Machines (SVM):** Busca el hiperplano de separaci贸n 贸ptimo.
*   **rboles de Decisi贸n y Random Forest:** Basados en reglas de decisi贸n jer谩rquicas.
*   **Naive Bayes:** Basado en probabilidad y el teorema de Bayes.
*   **Redes Neuronales:** Para patrones complejos y datos no estructurados.

---

### 3.4. Regresi贸n Log铆stica

A pesar de su nombre, la **Regresi贸n Log铆stica** es un algoritmo de **clasificaci贸n**, no de regresi贸n. Se utiliza para estimar la probabilidad de que una instancia pertenezca a una clase particular (por ejemplo, probabilidad de que un correo sea spam).

#### Conceptos B谩sicos y Matem谩ticos

La regresi贸n log铆stica utiliza la **funci贸n sigmoide** (o log铆stica) para transformar la salida de una ecuaci贸n lineal en un valor de probabilidad entre 0 y 1.

1.  **Funci贸n Lineal:** $z = w \cdot x + b$ (donde $w$ son los pesos y $x$ las caracter铆sticas).
2.  **Funci贸n Sigmoide:** $\sigma(z) = \frac{1}{1 + e^{-z}}$

Si la probabilidad estimada $\hat{p} = \sigma(z)$ es mayor o igual a 0.5, el modelo predice la clase 1; de lo contrario, predice la clase 0.

#### Algoritmo del Gradiente Descendente

Para entrenar el modelo, necesitamos encontrar los pesos $w$ y el sesgo $b$ que minimicen el error. La funci贸n de costo utilizada es la **Log Loss** (P茅rdida Logar铆tmica), ya que el error cuadr谩tico medio no es convexo para esta funci贸n.

El **Gradiente Descendente** es un algoritmo de optimizaci贸n iterativo:
1.  Inicializa los pesos aleatoriamente.
2.  Calcula el gradiente de la funci贸n de costo (la direcci贸n en la que el error aumenta m谩s r谩pido).
3.  Actualiza los pesos movi茅ndose en la direcci贸n opuesta al gradiente para reducir el error.
    $$w_{nuevo} = w_{viejo} - \eta \cdot \nabla Costo$$
    (Donde $\eta$ es la tasa de aprendizaje).

#### Ejemplo en Python

```python
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_breast_cancer
from sklearn.preprocessing import StandardScaler

# Cargar datos
data = load_breast_cancer()
X, y = data.data, data.target

# Dividir y Escalar (Importante para Gradiente Descendente)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Entrenar modelo
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)

# Predecir
y_pred = log_reg.predict(X_test)
```

---

### 3.5. M茅tricas de Rendimiento

Evaluar un clasificador va m谩s all谩 de simplemente contar cu谩ntos aciertos tuvo.

#### Matriz de Confusi贸n
Es una tabla que resume el rendimiento del modelo comparando las clases reales con las predichas.

| | Predicho Negativo (0) | Predicho Positivo (1) |
| :--- | :---: | :---: |
| **Real Negativo (0)** | **TN** (True Negative) | **FP** (False Positive) |
| **Real Positivo (1)** | **FN** (False Negative) | **TP** (True Positive) |

*   **TP:** Enfermos detectados correctamente.
*   **TN:** Sanos detectados correctamente.
*   **FP (Error Tipo I):** Sanos detectados err贸neamente como enfermos ("Falsa Alarma").
*   **FN (Error Tipo II):** Enfermos no detectados ("Peligroso").

#### M茅tricas Derivadas

1.  **Accuracy (Exactitud):** Proporci贸n total de predicciones correctas.
    $$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$$

2.  **Error Rate (Tasa de Error):** Proporci贸n de predicciones incorrectas.
    $$Error Rate = 1 - Accuracy = \frac{FP + FN}{Total}$$

3.  **Sensitivity / Recall / TPR (Tasa de Verdaderos Positivos):** Capacidad para detectar la clase positiva.
    $$Sensitivity = \frac{TP}{TP + FN}$$

4.  **Specificity / TNR (Tasa de Verdaderos Negativos):** Capacidad para detectar la clase negativa.
    $$Specificity = \frac{TN}{TN + FP}$$

5.  **False Positive Rate (FPR):**
    $$FPR = 1 - Specificity = \frac{FP}{TN + FP}$$

6.  **Precision (Precisi贸n):** De los que predije positivos, 驴cu谩ntos lo son realmente?
    $$Precision = \frac{TP}{TP + FP}$$

7.  **F1-Score (F-Measure):** Media arm贸nica de Precision y Recall. til cuando las clases est谩n desbalanceadas.
    $$F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}$$

8.  **Kappa Statistic (Cohen's Kappa):** Mide la concordancia entre la predicci贸n y la realidad, ajustada por el azar. Un valor de 1 es concordancia perfecta, 0 es igual al azar.

#### Ejemplo en Python

```python
from sklearn.metrics import confusion_matrix, classification_report, cohen_kappa_score

print("Matriz de Confusi贸n:\n", confusion_matrix(y_test, y_pred))
print("\nReporte de Clasificaci贸n:\n", classification_report(y_test, y_pred))
print(f"Kappa Score: {cohen_kappa_score(y_test, y_pred):.4f}")
```

---

### 3.6. Curva ROC y AUC

La **Curva ROC** (Receiver Operating Characteristic) es un gr谩fico que ilustra el rendimiento de un clasificador binario a medida que var铆a el umbral de discriminaci贸n.
*   **Eje X:** False Positive Rate (1 - Specificity).
*   **Eje Y:** True Positive Rate (Sensitivity).

Un modelo ideal se acerca a la esquina superior izquierda (TPR=1, FPR=0). La l铆nea diagonal representa un clasificador aleatorio.

**AUC (Area Under Curve):** Es el 谩rea bajo la curva ROC. Resume el rendimiento en un solo n煤mero.
*   AUC = 0.5: Aleatorio.
*   AUC = 1.0: Perfecto.

---

### 3.7. Sensibilidad, Especificidad y el Teorema de Bayes

Estos conceptos est谩n 铆ntimamente ligados al Teorema de Bayes cuando queremos calcular la probabilidad real de tener una condici贸n dado un resultado positivo en un test (Probabilidad a Posteriori).

Supongamos un test m茅dico para una enfermedad rara:
*   $P(E)$: Probabilidad a priori de tener la enfermedad (Prevalencia).
*   $P(+|E)$: Sensibilidad del test.
*   $P(-|No E)$: Especificidad del test.

Si un paciente da positivo, 驴cu谩l es la probabilidad de que realmente tenga la enfermedad $P(E|+)$?

$$P(E|+) = \frac{P(+|E) \cdot P(E)}{P(+|E) \cdot P(E) + P(+|No E) \cdot P(No E)}$$

Donde $P(+|No E)$ es el False Positive Rate ($1 - Especificidad$).
Este c谩lculo demuestra que si la prevalencia de la enfermedad es muy baja, incluso un test con alta sensibilidad y especificidad puede generar muchos falsos positivos, haciendo que la probabilidad real de estar enfermo sea baja a pesar del resultado positivo.

---

 **Fecha de creaci贸n:** 19/11/2025
锔 **Autor:** Fran Garc铆a
