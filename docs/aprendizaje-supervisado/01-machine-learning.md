
#  Unidad 1. Machine Learning Basado en el An谩lisis de Datos

Esta unidad introduce los conceptos fundamentales del Machine Learning (ML), su flujo de trabajo, las herramientas clave de la biblioteca `scikit-learn` del lenguaje Python, y las metodolog铆as esenciales para la preparaci贸n, divisi贸n y preprocesamiento de datos.

---

### 1.1. 驴Qu茅 es el Machine Learning?

El Machine Learning (ML) se define como un campo de estudio que utiliza modelos estad铆sticos para aprender de los datos. Un aspecto clave es que modelos relativamente simples pueden realizar predicciones complejas.

#### Definiciones Clave

* **Definici贸n temprana (Samuel, 1959):** "Programar computadoras para que aprendan de la experiencia deber铆a eliminar la necesidad de gran parte de este esfuerzo de programaci贸n detallado".
* **Definici贸n moderna (Mitchell, 1997):** "Se dice que un programa de computadora aprende de la **experiencia E** con respecto a alguna clase de **tareas T** y una medida de **rendimiento P**, si su rendimiento en las tareas T, medido por P, mejora con la experiencia E".
* **Definici贸n matem谩tica (Ej. Regresi贸n Lineal):** Un modelo matem谩tico que intenta encontrar la relaci贸n 贸ptima entre variables. Por ejemplo, predecir ventas (Target, $y$) bas谩ndose en gastos de publicidad (Feature, $x$). El modelo $y = wx + b$ aprende los **par谩metros** $w$ (peso) y $b$ iterando desde valores arbitrarios ($f_1$) hasta un valor 贸ptimo ($f_3$) que minimiza el error.

#### ML y Otros Campos
El Machine Learning est谩 profundamente interconectado con otros campos:
* Es un subcampo de la **Inteligencia Artificial**.
* **Deep Learning** es un subcampo del Machine Learning.
* Se solapa significativamente con **Estad铆stica**, **Miner铆a de Datos** y **Reconocimiento de Patrones**.

#### Tipos de Machine Learning
Seg煤n el m茅todo de supervisi贸n, el ML se divide en:
1.  **Supervisado:** Se proporciona un patr贸n objetivo (datos etiquetados). El cap铆tulo se centra en este tipo, que incluye algoritmos como Regresi贸n Lineal, Regresi贸n Log铆stica, rboles de Decisi贸n, KNN, SVM y Redes Neuronales.
2.  **No Supervisado:** El patr贸n objetivo debe ser descubierto (datos no etiquetados). Incluye Clustering, PCA y An谩lisis de Asociaci贸n.
3.  **Refuerzo:** Se aprende mediante la optimizaci贸n de pol铆ticas (recompensas y castigos).

#### Flujo de Trabajo del Machine Learning
El proceso general para construir un modelo de ML es:
1.  **Definici贸n del Problema:** Comprender el objetivo de negocio.
2.  **Preparaci贸n de Datos:** Recolecci贸n de datos brutos (Raw Data) y preprocesamiento.
3.  **Machine Learning (Modelado):** Se divide la data en conjuntos de **Train** (Entrenamiento), **Validate** (Validaci贸n) y **Test** (Prueba).
4.  **Entrenamiento y Evaluaci贸n:** Esta fase incluye **Ingenier铆a de caracter铆sticas** (Feature engineering), **Modelado y optimizaci贸n** (entrenar el modelo con los datos), y **Evaluaci贸n de rendimiento** (Performance metrics).
5.  **Aplicaci贸n:** Aplicar el modelo en la vida real.

#### Par谩metros vs. Hiperpar谩metros
* **Par谩metros:** Se aprenden *desde los datos* durante el entrenamiento. Contienen el patr贸n de los datos (ej. $w$ y $b$ en regresi贸n lineal, pesos de una red neuronal).
* **Hiperpar谩metros:** Se configuran *manualmente* por el practicante *antes* del entrenamiento. Se "afinan" (tunan) para optimizar el rendimiento (ej. el valor $k$ en KNN, la tasa de aprendizaje, la profundidad m谩xima de un 谩rbol).

---

### 1.2. Biblioteca Python scikit-learn

`scikit-learn` es la biblioteca de ML m谩s representativa de Python.

#### Caracter铆sticas
* Proporciona una interfaz de biblioteca integrada y unificada.
* Incluye una amplia variedad de algoritmos de ML, funciones de preprocesamiento y selecci贸n de modelos.
* Es simple, eficiente y est谩 construida sobre **NumPy, SciPy y matplotlib**.
* Es de c贸digo abierto y puede usarse comercialmente.
* **No soporta GPU**.

#### Mecanismo de `scikit-learn`
El flujo de trabajo de la API de `scikit-learn` es intuitivo y sigue tres pasos:
1.  **Instance:** Crear una instancia del objeto del modelo (Estimator).
2.  **Fit:** Entrenar el modelo con los datos.
3.  **Predict / transform:** Usar el modelo entrenado para hacer predicciones o transformar datos.



#### Estimator, Classifier y Regressor
* **`Estimator`:** El objeto base. Aprende de los datos usando el m茅todo `.fit()` y puede hacer predicciones usando `.predict()`.
* **`Classifier`:** Un estimador para tareas de clasificaci贸n (ej. `DecisionTreeClassifier`, `KNeighborsClassifier`).
* **`Regressor`:** Un estimador para tareas de regresi贸n (predicci贸n num茅rica) (ej. `LinearRegression`, `KNeighborsRegressor`).

#### Sintaxis B谩sica de `scikit-learn`
* **Importar un estimador:**
    `from sklearn.linear_model import LinearRegression`
* **Importar un preprocesador:**
    `from sklearn.preprocessing import StandardScaler`
* **Importar divisi贸n de datos:**
    `from sklearn.model_selection import train_test_split`
* **Importar m茅tricas:**
    `from sklearn import metrics`

* **Instanciar (con hiperpar谩metros):**
    `myModel = KNeighborsClassifier(n_neighbors=10)`
* **Dividir los datos (Hold-out):**
    `X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)`
* **Entrenar el modelo (Supervisado):**
    `myModel.fit(X_train, Y_train)`
* **Hacer predicciones:**
    `Y_pred = myModel.predict(X_test)`
* **Evaluar el rendimiento:**
    `metrics.accuracy_score(Y_test, Y_pred)`
* **Afinar hiperpar谩metros (con Cross-Validation):**
    `myGridCV = GridSearchCV(estimator, parameter_grid, cv=5)`

#### Ejemplo Pr谩ctico: Estandarizaci贸n
El preprocesamiento, como la **estandarizaci贸n**, es crucial para mejorar el rendimiento. La estandarizaci贸n (o *z-transformation*) convierte los datos para que sigan una distribuci贸n normal est谩ndar, usando la f贸rmula $z = \frac{x - m}{\sigma}$ (donde $m$ es la media y $\sigma$ la desviaci贸n est谩ndar).

En `scikit-learn`, se usa `StandardScaler`:
1.  **Importar:** `from sklearn.preprocessing import StandardScaler`
2.  **Instanciar:** `scaler = StandardScaler()`
3.  **Ajustar (Fit):** Se aprende la media ($m$) y la desviaci贸n ($\sigma$) **solo de los datos de entrenamiento**:
    `scaler.fit(X_train)`
4.  **Transformar:** Se aplica la transformaci贸n a los datos de entrenamiento y prueba:
    `X_train = scaler.transform(X_train)`
    `X_test = scaler.transform(X_test)`
5.  **`fit_transform`:** Se pueden combinar los pasos 3 y 4 (solo para `X_train`):
    `X_train = scaler.fit_transform(X_train)`

Antes de la estandarizaci贸n, las columnas pueden tener rangos de valores muy diferentes. Despu茅s, todos los valores est谩n centrados alrededor de 0, lo que ayuda a muchos algoritmos a converger mejor.

#### M贸dulos Principales de `scikit-learn`

| M贸dulo | Funci贸n Principal | Ejemplos |
| :--- | :--- | :--- |
| `sklearn.datasets` | Cargar datasets de ejemplo. | `load_iris()`, `load_breast_cancer()` |
| `sklearn.preprocessing` | Preprocesamiento de datos (escalado, codificaci贸n). | `StandardScaler`, `LabelEncoder`, `OneHotEncoder` |
| `sklearn.model_selection` | Divisi贸n de datos, validaci贸n y afinado de hiperpar谩metros. | `train_test_split`, `GridSearchCV`, `KFold` |
| `sklearn.metrics` | Evaluaci贸n de rendimiento del modelo. | `accuracy_score`, `precision_score`, `recall_score`, `roc_auc_score` |
| `sklearn.linear_model` | Algoritmos lineales. | `LinearRegression`, `LogisticRegression` |
| `sklearn.tree` | Algoritmos de rboles de Decisi贸n. | `DecisionTreeClassifier` |
| `sklearn.neighbors` | Algoritmos de vecinos cercanos. | `KNeighborsClassifier` (K-NN) |
| `sklearn.svm` | Support Vector Machine (M谩quinas de Vectores de Soporte). | `SVC` |
| `sklearn.ensemble` | Algoritmos de Ensamblado (Ensemble). | `RandomForestClassifier`, `AdaBoostClassifier` |
| `sklearn.cluster` | Algoritmos de clustering (No supervisado). | `KMeans`, `DBSCAN` |
| `sklearn.pipeline` | Herramienta para encadenar pasos de preprocesamiento y modelado. | `Pipeline` |

---

### 1.3. Preparaci贸n y Divisi贸n del Dataset

La divisi贸n de datos es fundamental para evaluar un modelo de ML. El conjunto de datos general se divide en un conjunto de **entrenamiento** y uno de **evaluaci贸n (prueba)**.

#### Overfitting (Sobreajuste) y Generalizaci贸n
* **Generalizaci贸n:** Es la capacidad del modelo para predecir con precisi贸n datos nuevos que no ha visto antes.
* **Overfitting:** Ocurre cuando un modelo se ajusta *demasiado* a los datos de entrenamiento, aprendiendo incluso el ruido.
* **Underfitting (Subajuste):** Ocurre cuando un modelo es *demasiado simple* (baja capacidad) y no puede capturar el patr贸n subyacente de los datos.



> **El Dilema:** A medida que aumenta la complejidad (flexibilidad) del modelo:
> * El error en el **conjunto de entrenamiento** (Training set) siempre disminuye.
> * El error en el **conjunto de prueba** (Test set) disminuye al principio, pero luego comienza a *aumentar*. El punto donde el error de prueba empieza a subir es donde comienza el overfitting.

El conjunto de prueba es **esencial** para detectar el overfitting y seleccionar un modelo que generalice bien.

#### Cross-Validation (Validaci贸n Cruzada)
El conjunto de prueba (Test set) debe usarse **隆solo una vez!** al final, para la evaluaci贸n final.

Para evaluar el modelo *durante* el entrenamiento (por ejemplo, para afinar hiperpar谩metros), necesitamos una forma de simular un "conjunto de prueba" sin tocar el real. Para esto, dividimos el **conjunto de entrenamiento** (Training Data) en dos partes m谩s peque帽as: un nuevo conjunto de `Train` y un conjunto de `Cross Validate` (Validaci贸n).

**M茅todo: k-Fold Cross-Validation**
Es el m茅todo m谩s com煤n:
1.  Se subdivide el conjunto de entrenamiento (original) en *k* partes iguales (folds). (Usualmente k=10).
2.  Se itera *k* veces (rondas).
3.  En cada ronda, se usa 1 fold como conjunto de **validaci贸n** y los *k-1* folds restantes como conjunto de **entrenamiento**.
4.  Se calcula la m茅trica de rendimiento (ej. accuracy) en cada ronda.
5.  El rendimiento final del modelo es el **promedio** de las m茅tricas de las *k* rondas.



**M茅todo: Leave One Out (LOO)**
Es un caso extremo de k-Fold donde $k$ es igual al n煤mero total de muestras. Se entrena con todos los datos menos uno, y se valida con ese 煤nico dato. Es computacionalmente muy costoso.

---

### 1.4. Preprocesamiento de Datos

Preparar los datos es vital para un buen modelo. Esto incluye la limpieza (manejo de valores at铆picos y faltantes) y la transformaci贸n (escalado y codificaci贸n).

#### Manejo de Valores Faltantes (Missing Values)
Los valores faltantes (identificados en Python como `np.nan` o `NaN`) deben ser tratados.

**1. Identificaci贸n:**
Se pueden contar usando `df.isnull().sum()`.

**2. Eliminaci贸n (con Pandas `dropna()`):**
* `df.dropna()`: Elimina cualquier **fila** que contenga al menos un `NaN` (eje por defecto 0).
* `df.dropna(axis=1)`: Elimina cualquier **columna** que contenga un `NaN`.
* `df.dropna(how='all')`: Elimina filas/columnas donde **todos** los valores son `NaN`.
* `df.dropna(thresh=N)`: Mantiene las filas que tienen al menos `N` valores no-`NaN`.
* `df.dropna(subset=['col_name'])`: Elimina filas que tienen `NaN` espec铆ficamente en la columna 'col_name'.

**3. Imputaci贸n (Relleno):**
Se usa cuando eliminar datos resultar铆a en una p茅rdida significativa de informaci贸n.
* **M茅todos simples:** Rellenar con un valor (ej. 'unknown'), la media, la mediana o el valor m谩s frecuente (moda) de la columna.
* **Con `scikit-learn` (`SimpleImputer`):** Es el m茅todo preferido.
    * `from sklearn.impute import SimpleImputer`
    * `impt = SimpleImputer(strategy='mean')` (Estrategias: 'mean', 'median', 'most_frequent').
    * `impt.fit(X_train)`: Aprende la media (o mediana/moda) del set de entrenamiento.
    * `X_train_imputed = impt.transform(X_train)`: Aplica la imputaci贸n.
    * `X_test_imputed = impt.transform(X_test)`: Aplica la *misma* imputaci贸n (con la media de train) al set de prueba.

#### Manejo de Datos Categ贸ricos
Los algoritmos de ML requieren entradas num茅ricas. Los datos categ贸ricos deben ser convertidos.

**1. Datos Ordinales (con orden):**
Ej. Tallas: 'M' < 'L' < 'XL'.
Se deben mapear a enteros que respeten ese orden.
* `size_mapping = {'M': 1, 'L': 2, 'XL': 3}`
* `df['size'] = df['size'].map(size_mapping)`

**2. Datos Nominales (sin orden) y Etiquetas de Clase:**
Ej. Colores: 'red', 'green', 'blue' o Etiquetas: 'setosa', 'versicolor'.

* **Codificaci贸n de Etiquetas (Label Encoding):**
    Convierte cada etiqueta 煤nica en un entero (ej. 'class1': 0, 'class2': 1). Se usa `LabelEncoder` de `scikit-learn`.
    * `from sklearn.preprocessing import LabelEncoder`
    * `enc = LabelEncoder()`
    * `y_encoded = enc.fit_transform(df['classlabel'])`

* **One-Hot Encoding (para caracter铆sticas nominales):**
    Usar `LabelEncoder` para caracter铆sticas (X) es incorrecto, ya que crea un orden artificial. Se debe usar **One-Hot Encoding**.
    Crea nuevas columnas "dummy" (0 o 1) para cada categor铆a, indicando presencia (1) o ausencia (0).
    * **M茅todo Pandas:** `pd.get_dummies(df['species'])`.
    * **M茅todo `scikit-learn`:** `OneHotEncoder`. Este m茅todo es preferido en pipelines y a menudo devuelve una **matriz dispersa** (sparse matrix) para ahorrar memoria, ya que la mayor铆a de los valores ser谩n 0.

#### Divisi贸n de Datos Estratificada (Stratify)
Al usar `train_test_split`, si el dataset est谩 desbalanceado (ej. 90% clase A, 10% clase B), una divisi贸n aleatoria simple podr铆a resultar en un set de prueba sin muestras de la clase B.
* **Soluci贸n:** Usar el par谩metro `stratify=y`.
* Esto asegura que la proporci贸n de las clases (ej. 90/10) se mantenga *id茅ntica* tanto en el conjunto de entrenamiento como en el de prueba, reflejando el dataset original.

#### T贸picos Avanzados: Tradeoff de Sesgo-Varianza y Regularizaci贸n
* **Tradeoff de Sesgo-Varianza:**
    * **Sesgo (Bias):** Error por suposiciones incorrectas (Underfitting).
    * **Varianza (Variance):** Error por sensibilidad excesiva a los datos de entrenamiento (Overfitting).
    * **Error Total $\approx$ Sesgo虏 + Varianza**. El objetivo es encontrar la complejidad 贸ptima que minimice este error total.
* **Regularizaci贸n:** T茅cnica para prevenir el overfitting en modelos lineales penalizando coeficientes (pesos) grandes.
    * **Ridge (L2):** A帽ade una penalizaci贸n $\lambda\sum{w_j^2}$. Encoge los pesos, pero no los hace cero.
    * **Lasso (L1):** A帽ade una penalizaci贸n $\lambda\sum{|w_j|}$. Puede forzar que algunos pesos sean exactamente cero, realizando una selecci贸n de caracter铆sticas autom谩tica.
    * **ElasticNet:** Combina penalizaciones L1 y L2.

---

### 1.5. Pr谩ctica: Soluci贸n de Problemas con scikit-learn (Ej. Iris)

Esta secci贸n aplica todos los conceptos anteriores en un caso pr谩ctico completo usando el dataset "Iris".

#### 1. Entendimiento del Problema y Datos (EDA)
* **Objetivo:** Clasificar la especie de una flor Iris (Target).
* **Clases (Target):** 3 especies (Setosa, Versicolor, Virginica).
* **Caracter铆sticas (Features):** `sepal_length`, `sepal_width`, `petal_length`, `petal_width`.
* **An谩lisis de Datos:**
    * Se cargan los datos y se convierten a un DataFrame de Pandas.
    * **Valores Faltantes:** Se comprueba con `iris.isnull().sum()`. No se encontraron.
    * **Distribuci贸n de Clases:** Se comprueba con `iris.groupby('target').size()`. Hay 50 muestras de cada clase (33.3% cada una). Es un **dataset balanceado**.
    * **Estad铆sticas y Correlaci贸n:** `iris.describe()` y `iris.corr()`. Se observa que `petal_length` y `petal_width` est谩n altamente correlacionados (0.96), sugiriendo un problema de multicolinealidad.
    * **Visualizaci贸n:** Se usan `pairplot` y `heatmap` para confirmar visualmente las relaciones y la alta correlaci贸n.

#### 2. Divisi贸n y Preparaci贸n de Datos
* **Separaci贸n X/y:** Se separan las caracter铆sticas (X) del objetivo (y).
* **Divisi贸n Train/Test:** Se usa `train_test_split` (ej. 80% train, 20% test).
* **Validaci贸n Cruzada:**
    * Se muestra c贸mo usar `KFold` (CV est谩ndar) y `StratifiedKFold` (CV estratificada).
    * `StratifiedKFold` es preferible porque mantiene la distribuci贸n 33/33/33 de las clases en cada fold, asegurando que la validaci贸n sea representativa.

#### 3. Selecci贸n y Evaluaci贸n del Modelo
* **Curva de Aprendizaje (`Learning Curve`):**
    Se usa para diagnosticar bias vs. variance. Muestra el rendimiento del modelo a medida que ve m谩s datos de entrenamiento.
* **Afinado de Hiperpar谩metros (`GridSearchCV`):**
    Se utiliza para encontrar la mejor combinaci贸n de hiperpar谩metros (ej. `criterion`, `max_depth` para un `DecisionTreeClassifier`) probando todas las combinaciones posibles mediante validaci贸n cruzada.

#### 4. M茅tricas de Evaluaci贸n (Clasificaci贸n)
Una vez que el modelo (`GridSearchCV`) est谩 entrenado y se hacen predicciones sobre el `X_test`, se eval煤a el rendimiento.

* **Matriz de Confusi贸n (`Confusion Matrix`):**
    Es la base para todas las m茅tricas. Compara los valores reales (True label) con los predichos (Predicted label).
    * **TP (True Positive):** Real = 1, Predicho = 1.
    * **FN (False Negative):** Real = 1, Predicho = 0.
    * **FP (False Positive):** Real = 0, Predicho = 1.
    * **TN (True Negative):** Real = 0, Predicho = 0.

* **M茅tricas Clave:**
    * **Accuracy (Exactitud):** $\frac{TP + TN}{Total}$. Proporci贸n de predicciones correctas. (Usar con cuidado en datasets desbalanceados).
    * **Precision (Precisi贸n):** $\frac{TP}{TP + FP}$. De los que *dijimos* que eran positivos, 驴cu谩ntos acertamos?.
    * **Recall (Sensibilidad o TPR):** $\frac{TP}{TP + FN}$. De *todos los positivos reales*, 驴cu谩ntos encontramos?.
    * **F1-Score:** La media arm贸nica de Precision y Recall. Es una m茅trica excelente para datasets desbalanceados. $F_1 = 2 \frac{Precision \times Recall}{Precision + Recall}$.
    * **FPR (Tasa de Falsos Positivos):** $\frac{FP}{FP + TN}$. Proporci贸n de negativos reales que clasificamos incorrectamente como positivos.

* **Curva ROC y AUC:**
    * **Curva ROC:** Gr谩fica que muestra el rendimiento de un clasificador en todos los umbrales de clasificaci贸n. Muestra **TPR** (Eje Y) vs. **FPR** (Eje X).
    * **AUC (Area Under the Curve):** El 谩rea bajo la curva ROC. Es una m茅trica 煤nica que resume el rendimiento del modelo.
        * AUC = 1.0: Clasificador perfecto.
        * AUC = 0.5: Clasificador in煤til (aleatorio).
        * Un AUC de 0.85 o m谩s se considera bueno.

#### 5. Predicci贸n Final
* Se carga el modelo final (el mejor `estimator_` encontrado por `GridSearchCV`).
* Se realizan las predicciones finales sobre el conjunto de prueba (`X_test`).
* Los resultados se guardan, por ejemplo, en un archivo CSV.

---

 **Fecha de creaci贸n:** 27/10/2025  
锔 **Autor:** Fran Garc铆a

